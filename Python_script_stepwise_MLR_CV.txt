import pandas as pd
import numpy as np
import statsmodels.api as sm
import matplotlib.pyplot as plt
from sklearn.model_selection import KFold
from sklearn.metrics import mean_squared_error, mean_absolute_error
from google.colab import drive  # For Google Colab (if applicable)

drive.mount('/content/drive')

# File path (Google Drive link should be manually uploaded/mounted to access the file)
file_path = "Your file path"
sheet_name = "Modeling_data" # replace by the actual sheet name

def calculate_aicc(model, n, k):
    """Calculates the corrected Akaike Information Criterion (AICc)."""
    aic = model.aic
    aicc = aic + (2 * k * (k + 1)) / (n - k - 1) if n > k + 1 else np.inf
    return aicc

def load_dataset(file_path, sheet_name):
    """Loads the dataset from an Excel file."""
    df = pd.read_excel(file_path, sheet_name=sheet_name)
    df.columns = df.columns.str.strip()
    df.replace(".", np.nan, inplace=True)
    print(f"‚úÖ Dataset loaded with {df.shape[0]} rows and {df.shape[1]} columns.")
    return df

# Handling categorial variables such as soil order
def preprocess_data(df, target="Bulk_density"): # replace by the actual column name
    """Prepares the dataset by handling missing values while keeping 'Soil_Order' as a categorical predictor."""
    print(f"üìä Initial dataset size: {df.shape}")

    if "Soil_Order" in df.columns: # replace by the actual variable name
        df["Soil_Order"] = df["Soil_Order"].astype("category")

    # Convert all columns to numeric, forcing non-numeric to NaN
    for col in df.columns:
        if col != "Soil_Order":
            df[col] = pd.to_numeric(df[col], errors='coerce')

    # ---CHANGE START---
    # Instead of converting the entire DataFrame, convert only numeric columns
    numeric_cols = df.select_dtypes(include=["number"]).columns.tolist()
    df[numeric_cols] = df[numeric_cols].astype('float64')
    # ---CHANGE END---

    # Drop specified columns if needed
    columns_to_remove = ["x,"y"] # replace x and y by the name of the variables
    
    # Remove columns only if they exist in the DataFrame
    columns_dropped = [col for col in columns_to_remove if col in df.columns]
    if columns_dropped:
        df.drop(columns=columns_dropped, inplace=True) # Indent this line
        print(f"\nüîπ Dropped columns: {columns_dropped}")

    numeric_cols = df.select_dtypes(include=["number"]).columns.tolist()
    missing_threshold = 20
    missing_percentages = df[numeric_cols].isnull().sum() / len(df) * 100
    columns_to_drop = missing_percentages[missing_percentages > missing_threshold].index.tolist()

    if columns_to_drop:
        print(f"\nüîπ Dropped features (> {missing_threshold}% missing values): {columns_to_drop}")
        df.drop(columns=columns_to_drop, inplace=True)

    initial_samples = df.shape[0]
    df.dropna(inplace=True)
    removed_samples = initial_samples - df.shape[0]

    if removed_samples > 0:
        print(f"\nüîπ Removed {removed_samples} samples due to missing values.")

    if target not in df.columns:
        raise ValueError(f"‚ùå Target column '{target}' not found.")

    # Convert categorical variable 'Soil_Order' into dummy variables
    if "Soil_Order" in df.columns:
        df = pd.get_dummies(df, columns=["Soil_Order"], drop_first=True)

    X = df.drop(columns=[target])
    y = df[target]
    
    # ---CHANGE START---
    # Explicitly convert all columns in X to numeric
    for col in X.columns:
        X[col] = pd.to_numeric(X[col], errors='coerce') # Convert to numeric, invalid parsing will be set as NaN
    X = X.select_dtypes(include=np.number) # Select only numeric columns
    # ---CHANGE END---

    print(f"\n‚úÖ Final dataset size: {X.shape[0]} samples, {X.shape[1]} features")

    if X.shape[0] == 0:
        raise ValueError("‚ùå No valid samples remain.")

    return X, y

def stepwise_regression(X, y):
    """Performs stepwise multiple regression using AICc for variable selection."""
    X = sm.add_constant(X)  # Ensure constant is added
    selected_vars = ["const"]
    remaining_vars = list(X.columns)
    remaining_vars.remove("const")
    best_model = None
    best_aicc = np.inf

    while remaining_vars:
        best_var = None
        for var in remaining_vars:
            model = sm.OLS(y, X[selected_vars + [var]]).fit()
            aicc = calculate_aicc(model, len(y), len(selected_vars) + 1)
            if aicc < best_aicc:
                best_aicc = aicc
                best_var = var
        if best_var:
            selected_vars.append(best_var)
            remaining_vars.remove(best_var)
            best_model = sm.OLS(y, X[selected_vars]).fit()
        else:
            break

    return best_model, selected_vars

def k_fold_cv(X, y, selected_vars, k=10):
    """Performs 10-Fold Cross-Validation to properly evaluate model performance."""
    print("üöÄ Performing 10-Fold Cross-Validation...")
    kf = KFold(n_splits=k, shuffle=True, random_state=42)
    results = []
    all_predictions = []

    for fold, (train_index, test_index) in enumerate(kf.split(X), 1):
        X_train, X_test = X.iloc[train_index], X.iloc[test_index]
        y_train, y_test = y.iloc[train_index], y.iloc[test_index]

       # Ensure the test set has the selected features AND add constant here
        X_train = sm.add_constant(X_train[selected_vars[1:]]) # Exclude 'const' and add it using sm.add_constant
        X_test = sm.add_constant(X_test[selected_vars[1:]]) # Exclude 'const' and add it using sm.add_constant

        model = sm.OLS(y_train, X_train).fit()
        predictions = model.predict(X_test)

        fold_metrics = {
            "Fold": fold,
            "RMSE": np.sqrt(mean_squared_error(y_test, predictions)),
            "MAE": mean_absolute_error(y_test, predictions),
            "R2": model.rsquared
        }
        results.append(fold_metrics)

        fold_predictions = pd.DataFrame({"Fold": fold, "Actual": y_test, "Predicted": predictions})
        all_predictions.append(fold_predictions)

        print(f"\nüîπ Fold {fold}: RMSE={fold_metrics['RMSE']:.4f}, MAE={fold_metrics['MAE']:.4f}, R¬≤={fold_metrics['R2']:.4f}")

    return pd.DataFrame(results), pd.concat(all_predictions)

def run_analysis(file_path, sheet_name):
    print("Loading dataset...")
    df = load_dataset(file_path, sheet_name)
    print("Preparing dataset...")
    X, y = preprocess_data(df)

    print("\n‚úÖ Preprocessing completed successfully!")
    
    # üîπPerform stepwise regression ONCE on the full dataset
    final_model, selected_vars = stepwise_regression(X, y)
    print(f"Selected Variables: {selected_vars}")

    # Extract the intercept separately
    intercept = final_model.params["const"]
    
    # Construct the equation string
    model_equation = f"Bulk Density = {intercept:.4f} " + " + ".join(
        [f"({coef:.4f} * {name})" for name, coef in final_model.params.items() if name != "const"]
    )
    
    print("\nModel Equation:")
    print(model_equation)

   # üîπPerform k-fold cross-validation and get results
    metrics_df, predictions_df = k_fold_cv(X, y, selected_vars) # Call k_fold_cv and store the results
    
    # Access Sample_ID using the original index from predictions_df
    # Get the original index values from predictions_df
    original_indices = predictions_df.index.get_level_values(0) if isinstance(predictions_df.index, pd.MultiIndex) else predictions_df.index
    # Use these original index values to select 'Sample_ID' from the original DataFrame
    predictions_df['Sample_ID'] = df.loc[original_indices, 'Sample_ID'].values

    # Create DataFrames for equation and model summary
    equation_df = pd.DataFrame({"Equation": [model_equation]}) # Create a DataFrame for the equation
    model_summary_df = pd.DataFrame(final_model.params.items(), columns=["Variable", "Coefficient"]) # Create DataFrame for coefficients

    # Corrected variable importance calculation with ranking
    coef_df = pd.DataFrame({"Variable": selected_vars, "Coefficient": final_model.params[selected_vars].abs()})
    coef_df = coef_df.sort_values(by="Coefficient", ascending=False)
    coef_df["Rank"] = range(1, len(coef_df) + 1)  # Add ranking column

    # üîπ Save all results to Excel
    results_file = "your folder path"
    with pd.ExcelWriter(results_file) as writer:
        metrics_df.to_excel(writer, sheet_name="10Fold_CV_Results", index=False)
        predictions_df.to_excel(writer, sheet_name="Predictions", index=False)
        equation_df.to_excel(writer, sheet_name="Model_Equation", index=False)
        model_summary_df.to_excel(writer, sheet_name="Model_Coefficients", index=False)
        coef_df.to_excel(writer, sheet_name="Variable_Importance", index=False)  # Includes rank

    print(f"Results saved to Google Drive: {results_file}")
    print("Model training complete.")

# Run the analysis
run_analysis(file_path, sheet_name)